{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.init # for initialization\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import dataset as d\n",
    "import util as u\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py # making dataset (or db) file maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageFolder dataset --> dataset.py used folder.py obj\n",
    "#all jpgs need to be wrapped by the directory of having the same number\n",
    "vist_train=d.ImgDset_Folder(Path(\"./data/train\"))  \n",
    "vist_val=d.ImgDset_Folder(Path(\"./data/val\"))  \n",
    "vist_test=d.ImgDset_Folder(Path(\"./data/test\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, PosixPath('data/train'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vist_train.img_names), vist_train.img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=1 \n",
    "batch_size=4\n",
    "test_loader = torch.utils.data.DataLoader(dataset=vist_test,\n",
    "                                          batch_size=batch_size,                 #no batch needed\n",
    "                                          shuffle=False,                #no need to shuffle: feature extraction\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model here\n",
    "Resnet=models.resnet50(pretrained=True) #pretrained on \"ImageNet\", \n",
    "                                        #expects identically normalized/shaped inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet.cuda() #no graphic driver for desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test=len(vist_test)\n",
    "test_name_list=vist_test.img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_id2idx : dict for fname to hdf5_idx\n",
    "test_hdf_index=[str(i) for i in range(len_test)]\n",
    "test_id2idx=dict(zip(test_name_list, test_hdf_index))\n",
    "\n",
    "\n",
    "hdf=h5py.File(\"VIST_resnet50.hdf5\", \"w\")\n",
    "test_ds=hdf.create_dataset(\"VIST_test\",(len_test,1000), dtype='float32' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tfilename: 2.png is read \n",
      "\tfeaturebatch shape: torch.Size([4, 1000])\n",
      "<built-in method format of str object at 0x7f9d9506ed20>\n"
     ]
    }
   ],
   "source": [
    "for idx,imgbatch in enumerate(test_loader):\n",
    "    \n",
    "    \n",
    "    X=Variable(imgbatch, volatile=True) #to avoid memory prob?\n",
    "    featurebatch=Resnet(X)\n",
    "    print(\"\\n\\tfilename: {original} is read \".format(original=test_name_list[idx]))\n",
    "    print(\"\\tfeaturebatch shape: {fshape}\".format(fshape=featurebatch.shape))\n",
    "    test_ds[idx:idx+batch_size]=featurebatch.data.numpy()\n",
    "    \n",
    "    idx+=batch_size\n",
    "\n",
    "hdf.close()\n",
    "print(\"\\tsaved as {hdf5}\".format )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업개요   \n",
    "### 작업 시간 1+1+3시간   \n",
    ">쓸데없는 제안서만 아니었어도 더 했을건데 기다리게 해서 죄송합니다ㅠ\n",
    "\n",
    "### 만났던 난관들:   \n",
    ">- dataset 어떻게 만들지? 뭔가 torchvision.dataset.ImageFolder 쓰다가 아님을 깨닫고 버림, github에서 folder.py 보고 dataset.py 구성   \n",
    "- 하나씩 로드 -> feature -> hdf5 append 가 계획인데 그러는데 dataloader는 아닌거같아서...? 일단 만들고 냅둠  \n",
    "- 뭔가 차원이 안맞네 np.ndarray[None,:,:,:]   \n",
    "\n",
    "### 지금 마주한 문제:   \n",
    ">- hdf5 이거 어떻게 쓰는건지 (현재)\n",
    "\n",
    "### 해결사 킹갇전재현 찬양경배해!\n",
    ">- 혼자 배우는 것도 좋지만 적절한 피드백이 배움에 큰 도움이 되는 걸 새삼 느낀다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
