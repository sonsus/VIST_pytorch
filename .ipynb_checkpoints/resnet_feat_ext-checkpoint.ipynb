{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.init # for initialization\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import dataset as d\n",
    "import util as u\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py # making dataset (or db) file maybe\n",
    "import pickle # pkl?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageFolder dataset\n",
    "#all jpgs need to be wrapped by the directory of having the same number\n",
    "vist_train=d.ImgDset_Folder(Path(\"./data/train\"))  \n",
    "vist_val=d.ImgDset_Folder(Path(\"./data/val\"))  \n",
    "vist_test=d.ImgDset_Folder(Path(\"./data/test\"))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.png'], PosixPath('data/train'), 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vist_train.img_names, vist_train.img_path, len(vist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=1 \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=vist_test,\n",
    "                                          batch_size=10,                 #no batch needed\n",
    "                                          shuffle=False,                #no need to shuffle: feature extraction\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model here\n",
    "Resnet=models.resnet50(pretrained=True) #pretrained on \"ImageNet\", \n",
    "                                        #expects identically normalized/shaped inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet.cuda() #no graphic driver for desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test=len(vist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"VISTresnetfeat\": shape (4, 1, 1000), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tt=transforms.ToTensor\n",
    "#for i in range(10):\n",
    "#    a=tt.__call__(tt,pic=dsets.folder.pil_loader(vist_train.imgs[i][0]))[2][50][10:20]\n",
    "#    b=tt.__call__(tt,vist_train[i][0])[2][50][10:20]\n",
    "#    print(a==b)\n",
    "\n",
    "\n",
    "test_name_list=vist_test.img_names\n",
    "test_hdf_index=[str(i) for i in range(len_test)]\n",
    "test_id2idx=dict(zip(test_name_list, test_hdf_index))\n",
    "\n",
    "\n",
    "\n",
    "hdf=h5py.File(\"VIST_resnet.hdf5\", \"w\")\n",
    "hdf.create_dataset(\"VISTresnetfeat\",(len_test,1,1000) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len_test):\n",
    "    \n",
    "    img=vist_test[idx]\n",
    "    img_=img[None,:,:,:]\n",
    "    \n",
    "    \n",
    "    X=Variable(img_)\n",
    "    #X=Variable(img).cuda()\n",
    "    feature=Resnet(X)\n",
    "    print(\"\\n\\tfilename: {original} is read \".format(original=test_name_list[idx]))\n",
    "    print(\"\\tfeature shape: {fshape}\".format(fshape=feature.shape))\n",
    "\n",
    "    fname=test_name_list[idx] # extension stripped out\n",
    "    hdf[test_id2idx[fname]]=feature\n",
    "\n",
    "print(\"\\tsaved as {hdf5}\".format )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업개요   \n",
    "### 작업 시간 1+1+3시간   \n",
    ">쓸데없는 제안서만 아니었어도 더 했을건데 기다리게 해서 죄송합니다ㅠ\n",
    "\n",
    "### 만났던 난관들:   \n",
    ">- dataset 어떻게 만들지? 뭔가 torchvision.dataset.ImageFolder 쓰다가 아님을 깨닫고 버림, github에서 folder.py 보고 dataset.py 구성   \n",
    "- 하나씩 로드 -> feature -> hdf5 append 가 계획인데 그러는데 dataloader는 아닌거같아서...? 일단 만들고 냅둠  \n",
    "- 뭔가 차원이 안맞네 np.ndarray[None,:,:,:]   \n",
    "\n",
    "### 지금 마주한 문제:   \n",
    ">- hdf5 이거 어떻게 쓰는건지 (현재)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">금방 할 줄 알았는데 안되네요 ㅎㅎㅎㅎ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 하나씩 로드하면 느리겠죠? 그래서 데이터로더로 배치로 해야하는데 일단 hdf5가 날 가로막는드아ㅏ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
